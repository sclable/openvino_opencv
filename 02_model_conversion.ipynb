{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conversion \n",
    "It converts pre-trained model from any of the popular frameworks to Intermediate Representation (IR) format with the \n",
    "desired precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: mo.py [options]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --framework {tf,caffe,mxnet,kaldi,onnx}\r\n",
      "                        Name of the framework used to train the input model.\r\n",
      "\r\n",
      "Framework-agnostic parameters:\r\n",
      "  --input_model INPUT_MODEL, -w INPUT_MODEL, -m INPUT_MODEL\r\n",
      "                        Tensorflow*: a file with a pre-trained model (binary\r\n",
      "                        or text .pb file after freezing). Caffe*: a model\r\n",
      "                        proto file with model weights\r\n",
      "  --model_name MODEL_NAME, -n MODEL_NAME\r\n",
      "                        Model_name parameter passed to the final create_ir\r\n",
      "                        transform. This parameter is used to name a network in\r\n",
      "                        a generated IR and output .xml/.bin files.\r\n",
      "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\r\n",
      "                        Directory that stores the generated IR. By default, it\r\n",
      "                        is the directory from where the Model Optimizer is\r\n",
      "                        launched.\r\n",
      "  --input_shape INPUT_SHAPE\r\n",
      "                        Input shape(s) that should be fed to an input node(s)\r\n",
      "                        of the model. Shape is defined as a comma-separated\r\n",
      "                        list of integer numbers enclosed in parentheses or\r\n",
      "                        square brackets, for example [1,3,227,227] or\r\n",
      "                        (1,227,227,3), where the order of dimensions depends\r\n",
      "                        on the framework input layout of the model. For\r\n",
      "                        example, [N,C,H,W] is used for Caffe* models and\r\n",
      "                        [N,H,W,C] for TensorFlow* models. Model Optimizer\r\n",
      "                        performs necessary transformations to convert the\r\n",
      "                        shape to the layout required by Inference Engine\r\n",
      "                        (N,C,H,W). The shape should not contain undefined\r\n",
      "                        dimensions (? or -1) and should fit the dimensions\r\n",
      "                        defined in the input operation of the graph. If there\r\n",
      "                        are multiple inputs in the model, --input_shape should\r\n",
      "                        contain definition of shape for each input separated\r\n",
      "                        by a comma, for example: [1,3,227,227],[2,4] for a\r\n",
      "                        model with two inputs with 4D and 2D shapes.\r\n",
      "                        Alternatively, you can specify shapes with the --input\r\n",
      "                        option.\r\n",
      "  --scale SCALE, -s SCALE\r\n",
      "                        All input values coming from original network inputs\r\n",
      "                        will be divided by this value. When a list of inputs\r\n",
      "                        is overridden by the --input parameter, this scale is\r\n",
      "                        not applied for any input that does not match with the\r\n",
      "                        original input of the model.\r\n",
      "  --reverse_input_channels\r\n",
      "                        Switch the input channels order from RGB to BGR (or\r\n",
      "                        vice versa). Applied to original inputs of the model\r\n",
      "                        if and only if a number of channels equals 3. Applied\r\n",
      "                        after application of --mean_values and --scale_values\r\n",
      "                        options, so numbers in --mean_values and\r\n",
      "                        --scale_values go in the order of channels used in the\r\n",
      "                        original model.\r\n",
      "  --log_level {CRITICAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}\r\n",
      "                        Logger level\r\n",
      "  --input INPUT         Quoted list of comma-separated input nodes names with\r\n",
      "                        shapes, data types, and values for freezing. The shape\r\n",
      "                        and value are specified as space-separated lists. The\r\n",
      "                        data type of input node is specified in braces and can\r\n",
      "                        have one of the values: f64 (float64), f32 (float32),\r\n",
      "                        f16 (float16), i64 (int64), i32 (int32), u8 (uint8),\r\n",
      "                        boolean. For example, use the following format to set\r\n",
      "                        input port 0 of the node `node_name1` with the shape\r\n",
      "                        [3 4] as an input node and freeze output port 1 of the\r\n",
      "                        node `node_name2` with the value [20 15] of int32\r\n",
      "                        typeand the shape [2]: \"0:node_name1[3\r\n",
      "                        4],node_name2:1[2]{i32}->[20 15]\".\r\n",
      "  --output OUTPUT       The name of the output operation of the model. For\r\n",
      "                        TensorFlow*, do not add :0 to this name.\r\n",
      "  --mean_values MEAN_VALUES, -ms MEAN_VALUES\r\n",
      "                        Mean values to be used for the input image per\r\n",
      "                        channel. Values to be provided in the (R,G,B) or\r\n",
      "                        [R,G,B] format. Can be defined for desired input of\r\n",
      "                        the model, for example: \"--mean_values\r\n",
      "                        data[255,255,255],info[255,255,255]\". The exact\r\n",
      "                        meaning and order of channels depend on how the\r\n",
      "                        original model was trained.\r\n",
      "  --scale_values SCALE_VALUES\r\n",
      "                        Scale values to be used for the input image per\r\n",
      "                        channel. Values are provided in the (R,G,B) or [R,G,B]\r\n",
      "                        format. Can be defined for desired input of the model,\r\n",
      "                        for example: \"--scale_values\r\n",
      "                        data[255,255,255],info[255,255,255]\". The exact\r\n",
      "                        meaning and order of channels depend on how the\r\n",
      "                        original model was trained.\r\n",
      "  --data_type {FP16,FP32,half,float}\r\n",
      "                        Data type for all intermediate tensors and weights. If\r\n",
      "                        original model is in FP32 and --data_type=FP16 is\r\n",
      "                        specified, all model weights and biases are quantized\r\n",
      "                        to FP16.\r\n",
      "  --disable_fusing      Turn off fusing of linear operations to Convolution\r\n",
      "  --disable_resnet_optimization\r\n",
      "                        Turn off resnet optimization\r\n",
      "  --finegrain_fusing FINEGRAIN_FUSING\r\n",
      "                        Regex for layers/operations that won't be fused.\r\n",
      "                        Example: --finegrain_fusing Convolution1,.*Scale.*\r\n",
      "  --disable_gfusing     Turn off fusing of grouped convolutions\r\n",
      "  --enable_concat_optimization\r\n",
      "                        Turn on concat optimization\r\n",
      "  --move_to_preprocess  Move mean values to IR preprocess section\r\n",
      "  --extensions EXTENSIONS\r\n",
      "                        Directory or a comma separated list of directories\r\n",
      "                        with extensions. To disable all extensions including\r\n",
      "                        those that are placed at the default location, pass an\r\n",
      "                        empty string.\r\n",
      "  --batch BATCH, -b BATCH\r\n",
      "                        Input batch size\r\n",
      "  --version             Version of Model Optimizer\r\n",
      "  --silent              Prevent any output messages except those that\r\n",
      "                        correspond to log level equals ERROR, that can be set\r\n",
      "                        with the following option: --log_level. By default,\r\n",
      "                        log level is already ERROR.\r\n",
      "  --freeze_placeholder_with_value FREEZE_PLACEHOLDER_WITH_VALUE\r\n",
      "                        Replaces input layer with constant node with provided\r\n",
      "                        value, for example: \"node_name->True\". It will be\r\n",
      "                        DEPRECATED in future releases. Use --input option to\r\n",
      "                        specify a value for freezing.\r\n",
      "  --generate_deprecated_IR_V7\r\n",
      "                        Force to generate old deprecated IR V7 with layers\r\n",
      "                        from old IR specification.\r\n",
      "  --keep_shape_ops      [ Experimental feature ] Enables `Shape` operation\r\n",
      "                        with all children keeping. This feature makes model\r\n",
      "                        reshapable in Inference Engine\r\n",
      "  --progress            Enables model conversion progress display\r\n",
      "  --stream_output       Switches model conversion progress display to a\r\n",
      "                        multiline mode\r\n",
      "  --transformations_config TRANSFORMATIONS_CONFIG\r\n",
      "                        Use the configuration file with transformations\r\n",
      "                        description.\r\n",
      "\r\n",
      "TensorFlow*-specific parameters:\r\n",
      "  --input_model_is_text\r\n",
      "                        TensorFlow*: treat the input model file as a text\r\n",
      "                        protobuf format. If not specified, the Model Optimizer\r\n",
      "                        treats it as a binary file by default.\r\n",
      "  --input_checkpoint INPUT_CHECKPOINT\r\n",
      "                        TensorFlow*: variables file to load.\r\n",
      "  --input_meta_graph INPUT_META_GRAPH\r\n",
      "                        Tensorflow*: a file with a meta-graph of the model\r\n",
      "                        before freezing\r\n",
      "  --saved_model_dir SAVED_MODEL_DIR\r\n",
      "                        TensorFlow*: directory representing non frozen model\r\n",
      "  --saved_model_tags SAVED_MODEL_TAGS\r\n",
      "                        Group of tag(s) of the MetaGraphDef to load, in string\r\n",
      "                        format, separated by ','. For tag-set contains\r\n",
      "                        multiple tags, all tags must be passed in.\r\n",
      "  --tensorflow_subgraph_patterns TENSORFLOW_SUBGRAPH_PATTERNS\r\n",
      "                        TensorFlow*: a list of comma separated patterns that\r\n",
      "                        will be applied to TensorFlow* node names to infer a\r\n",
      "                        part of the graph using TensorFlow*.\r\n",
      "  --tensorflow_operation_patterns TENSORFLOW_OPERATION_PATTERNS\r\n",
      "                        TensorFlow*: a list of comma separated patterns that\r\n",
      "                        will be applied to TensorFlow* node type (ops) to\r\n",
      "                        infer these operations using TensorFlow*.\r\n",
      "  --tensorflow_custom_operations_config_update TENSORFLOW_CUSTOM_OPERATIONS_CONFIG_UPDATE\r\n",
      "                        TensorFlow*: update the configuration file with node\r\n",
      "                        name patterns with input/output nodes information.\r\n",
      "  --tensorflow_use_custom_operations_config TENSORFLOW_USE_CUSTOM_OPERATIONS_CONFIG\r\n",
      "                        Use the configuration file with custom operation\r\n",
      "                        description.\r\n",
      "  --tensorflow_object_detection_api_pipeline_config TENSORFLOW_OBJECT_DETECTION_API_PIPELINE_CONFIG\r",
      "\r\n",
      "                        TensorFlow*: path to the pipeline configuration file\r\n",
      "                        used to generate model created with help of Object\r\n",
      "                        Detection API.\r\n",
      "  --tensorboard_logdir TENSORBOARD_LOGDIR\r\n",
      "                        TensorFlow*: dump the input graph to a given directory\r\n",
      "                        that should be used with TensorBoard.\r\n",
      "  --tensorflow_custom_layer_libraries TENSORFLOW_CUSTOM_LAYER_LIBRARIES\r\n",
      "                        TensorFlow*: comma separated list of shared libraries\r\n",
      "                        with TensorFlow* custom operations implementation.\r\n",
      "  --disable_nhwc_to_nchw\r\n",
      "                        Disables default translation from NHWC to NCHW\r\n",
      "\r\n",
      "Caffe*-specific parameters:\r\n",
      "  --input_proto INPUT_PROTO, -d INPUT_PROTO\r\n",
      "                        Deploy-ready prototxt file that contains a topology\r\n",
      "                        structure and layer attributes\r\n",
      "  --caffe_parser_path CAFFE_PARSER_PATH\r\n",
      "                        Path to Python Caffe* parser generated from\r\n",
      "                        caffe.proto\r\n",
      "  -k K                  Path to CustomLayersMapping.xml to register custom\r\n",
      "                        layers\r\n",
      "  --mean_file MEAN_FILE, -mf MEAN_FILE\r\n",
      "                        Mean image to be used for the input. Should be a\r\n",
      "                        binaryproto file\r\n",
      "  --mean_file_offsets MEAN_FILE_OFFSETS, -mo MEAN_FILE_OFFSETS\r\n",
      "                        Mean image offsets to be used for the input\r\n",
      "                        binaryproto file. When the mean image is bigger than\r\n",
      "                        the expected input, it is cropped. By default, centers\r\n",
      "                        of the input image and the mean image are the same and\r\n",
      "                        the mean image is cropped by dimensions of the input\r\n",
      "                        image. The format to pass this option is the\r\n",
      "                        following: \"-mo (x,y)\". In this case, the mean file is\r\n",
      "                        cropped by dimensions of the input image with offset\r\n",
      "                        (x,y) from the upper left corner of the mean image\r\n",
      "  --disable_omitting_optional\r\n",
      "                        Disable omitting optional attributes to be used for\r\n",
      "                        custom layers. Use this option if you want to transfer\r\n",
      "                        all attributes of a custom layer to IR. Default\r\n",
      "                        behavior is to transfer the attributes with default\r\n",
      "                        values and the attributes defined by the user to IR.\r\n",
      "  --enable_flattening_nested_params\r\n",
      "                        Enable flattening optional params to be used for\r\n",
      "                        custom layers. Use this option if you want to transfer\r\n",
      "                        attributes of a custom layer to IR with flattened\r\n",
      "                        nested parameters. Default behavior is to transfer the\r\n",
      "                        attributes without flattening nested parameters.\r\n",
      "\r\n",
      "Mxnet-specific parameters:\r\n",
      "  --input_symbol INPUT_SYMBOL\r\n",
      "                        Symbol file (for example, model-symbol.json) that\r\n",
      "                        contains a topology structure and layer attributes\r\n",
      "  --nd_prefix_name ND_PREFIX_NAME\r\n",
      "                        Prefix name for args.nd and argx.nd files.\r\n",
      "  --pretrained_model_name PRETRAINED_MODEL_NAME\r\n",
      "                        Name of a pretrained MXNet model without extension and\r\n",
      "                        epoch number. This model will be merged with args.nd\r\n",
      "                        and argx.nd files\r\n",
      "  --save_params_from_nd\r\n",
      "                        Enable saving built parameters file from .nd files\r\n",
      "  --legacy_mxnet_model  Enable MXNet loader to make a model compatible with\r\n",
      "                        the latest MXNet version. Use only if your model was\r\n",
      "                        trained with MXNet version lower than 1.0.0\r\n",
      "  --enable_ssd_gluoncv  Enable pattern matchers replacers for converting\r\n",
      "                        gluoncv ssd topologies.\r\n",
      "\r\n",
      "Kaldi-specific parameters:\r\n",
      "  --counts COUNTS       Path to the counts file\r\n",
      "  --remove_output_softmax\r\n",
      "                        Removes the SoftMax layer that is the output layer\r\n",
      "  --remove_memory       Removes the Memory layer and use additional inputs\r\n",
      "                        outputs instead\r\n"
     ]
    }
   ],
   "source": [
    "# Check how to use the model downloader script\n",
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MODEL_FPATH = \"./models/custom_crack_detection/crack_detection.pb\"\n",
    "OUT_DIR = os.path.dirname(INPUT_MODEL_FPATH)\n",
    "DATA_TYPE = 'FP32'\n",
    "MODEL_NAME = 'fp32_crack_detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/Users/sanchit/Documents/Projects/openvino_opencv/./models/custom_crack_detection/crack_detection.pb\n",
      "\t- Path for generated IR: \t/Users/sanchit/Documents/Projects/openvino_opencv/./models/custom_crack_detection\n",
      "\t- IR output name: \tfp32_crack_detection\n",
      "\t- Log level: \tWARNING\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,352,640,3]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2020.1.0-61-gd349c3ba4a\n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementSubgraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.user_data_repack.UserDataRepack'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileGeneral'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileSubGraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementSubgraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.user_data_repack.UserDataRepack'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileGeneral'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileSubGraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.const.Const'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.gather.Gather'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.gather.AttributedGather'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.split.VariadicSplitBase'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.split.SplitBase'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.parameter.Parameter'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.tensor_iterator.TensorIterator'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.transpose.Transpose'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.clamp.Clamp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.activation_ops.Activation'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.activation_ops.LeakyReLU'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.concat.Concat'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.convolution.Convolution'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.crop.Crop'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.reshape.Reshape'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.softmax.Softmax'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.ops.Cast.Cast'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.activation.Activation'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.broadcast.Broadcast'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.constant_of_shape.ConstantOfShape'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.deconvolution.Deconvolution'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.deformable_convolution.DeformableConvolution'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.eltwise.Eltwise'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.eltwise_n.EltwiseN'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.eltwise_ninputs_in_1.EltwiseNin1'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.expand_dims.ExpandDims'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.fill.Fill'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.flatten.Flatten'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.flatten.FlattenONNX'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.group_norm.GroupNorm'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.lrn.LRN'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.lrn.AttributedLRN'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.lstmnonlinearity.LstmNonLinearity'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.memory.Memory'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.memoryoffset.MemoryOffset'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.pad.Pad'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.permute.Permute'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.pooling.Pooling'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.power.AttributedPower'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.result.Result'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.roipooling.ROIPooling'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.scale_shift.ScaleShiftOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.shape.Shape'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.slice.Slice'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.squeeze.Squeeze'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.strided_slice.StridedSlice'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.tile.Tile'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.tile.AttributedTile'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.ops.unsqueeze.Unsqueeze'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.utils.model_analysis.AnalysisCollectorAnchor'> registration because it was already registered or it was disabled. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  Skipped <class 'mo.front.tf.extractors.strided_slice.StridedSliceFrontExtractor'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementSubgraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.user_data_repack.UserDataRepack'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileGeneral'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileSubGraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.extractors.strided_slice.StridedSliceFrontExtractor'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.AttributedGatherNormalizer.AttributedGatherNormalizer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.InterpolateNormalizer.InterpolateNormalizer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.LRNReplacer.LRNReplacer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.Log1p.Log1p'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.Pack.Pack'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.PowerToEltwises.PowerToEltwises'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.tf.FakeQuantWithMinMaxVars.FakeQuantWithMinMaxVarsToQuantize'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.div.Div'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.eltwise_n.EltwiseNReplacement'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.rank_decomposer.RankDecomposer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.image_scaler.ImageScaler'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.instance_normalization.InstanceNormalization'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.reciprocal.ReciprocalReplacer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.sub.Sub'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.softsign_replacer.SoftSign'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.split_normalizer.SqueezeAxis'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.squared_difference.SquaredDifference'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementSubgraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.user_data_repack.UserDataRepack'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileGeneral'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.ChangePlaceholderTypes.ChangePlaceholderTypes'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.ExpandDimsToUnsqueeze.ExpandDimsToUnsqueeze'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.FillToBroadcast.FillToBroadcast'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.pass_separator.FrontStart'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.pass_separator.FrontFinish'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.SqueezeNormalize.SqueezeNormalize'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.TopKNormalize.TopKNormalize'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.binary_quantize_normalization.BinaryFakeQuantizeNormalization'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.create_tensor_nodes.CreateTensorNodes'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.disable_weights_quantize_value_propagation.DisableQuantizeValuePropagation'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.global_pooling_to_reduce.GlobalPoolingToReduce'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.input_cut.InputCut'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.output_cut.OutputCut'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.override_batch.OverrideBatch'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.transformations_config.TransformationsConfig'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.common.replacement.FrontReplacementOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileSubGraph'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.ArgMaxSqueeze.ArgMaxSqueeze'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.ChangeCastOutputType.ChangeCastOutputType'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.MatMul_normalizer.FullyConnectedDecomposer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.MatMul_normalizer.GemmDecomposer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.restore_ports.RestorePorts'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.MoveEmbeddedInputsToInputs.MoveEmbeddedInputsToInputs'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.TransposeOrderNormalizer.TransposeOrderNormalizer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.no_op_eraser.NoOpEraser'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.standalone_const_eraser.StandaloneConstEraser'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.flatten_to_reshape.FlattenToReshape'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.freeze_placeholder_value.FreezePlaceholderValue'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.reduce_axis_normalizer.ReduceAxisNormalizer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.reshape_dim_normalizer.ReshapeDimNormalizer'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.softmax.SoftmaxFromKeras'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.split_normalizer.SplitInputsReconnect'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.split_normalizer.AttributedSplitToSplit'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.split_normalizer.AttributedVariadicSplitToVariadicSplit'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.split_normalizer.VariadicSplitInputsSwap'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'mo.front.tf.replacement.FrontReplacementFromConfigFileOp'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.YOLO.YoloRegionAddon'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.front.YOLO.YoloV3RegionAddon'> registration because it was already registered or it was disabled. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  Skipped <class 'extensions.middle.pass_separator.PreMiddleStart'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.middle.pass_separator.MiddleStart'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.middle.pass_separator.MiddleFinish'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.middle.pass_separator.PostMiddleStart'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.middle.InsertLayoutPropagationTransposes.InsertLayoutPropagationTranspose'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.pass_separator.BackStart'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.pass_separator.BackFinish'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.SpecialNodesFinalization.RemoveConstOps'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.SpecialNodesFinalization.CreateConstNodesReplacement'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.SpecialNodesFinalization.RemoveOutputOps'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.SpecialNodesFinalization.NormalizeTI'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.RemoveUselessConvert.RemoveUselessConvert'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Skipped <class 'extensions.back.op_versioning.OpVersioning'> registration because it was already registered or it was disabled. \n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  Broadcast of scalar to shape: [0]\n",
      "[ WARNING ]  FusedBatchNorm doesn't support is_training=True\n",
      "[ WARNING ]  Broadcast of scalar to shape: [1]\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'TFYOLOV3' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'SSDToolboxDetectionOutput' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'RetinaNetFilteredDetectionsReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIOutputReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIConstValueOverride' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIPreprocessorReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIProposalReplacement' doesn't exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  Configuration file for custom replacement with id 'InterpolateTranspose' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPISSDPostprocessorReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'TFYOLO' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIDetectionOutputReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIPSROIPoolingReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIMaskRCNNROIPoolingSecondReplacement' doesn't exist\n",
      "[ WARNING ]  Configuration file for custom replacement with id 'ObjectDetectionAPIMaskRCNNSigmoidReplacement' doesn't exist\n",
      "[ WARNING ]  Converting type of Const node \"conv2d_transpose/conv2d_transpose/Cast_29393_const\" to \"<class 'numpy.int64'>\"\n",
      "[ WARNING ]  Converting type of Const node \"conv2d_transpose_1/conv2d_transpose/Cast_29391_const\" to \"<class 'numpy.int64'>\"\n",
      "[ WARNING ]  Converting type of Const node \"conv2d_transpose_2/conv2d_transpose/Cast_29397_const\" to \"<class 'numpy.int64'>\"\n",
      "[ WARNING ]  Converting type of Const node \"conv2d_transpose_3/conv2d_transpose/Cast_29389_const\" to \"<class 'numpy.int64'>\"\n",
      "[ WARNING ]  Converting type of Const node \"conv2d_transpose_4/conv2d_transpose/Cast_29395_const\" to \"<class 'numpy.int64'>\"\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"128\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"22\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"40\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"128\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"22\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"40\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"64\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"44\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"80\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"64\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"44\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"80\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"32\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"88\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"160\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"32\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"88\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"160\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"16\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"176\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"320\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"16\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"176\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"320\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"8\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"352\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"640\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"1\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"8\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"352\" to integer\n",
      "[ WARNING ]  The element of shape is not np.int64 value. Converting the value \"640\" to integer\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /Users/sanchit/Documents/Projects/openvino_opencv/./models/custom_crack_detection/fp32_crack_detection.xml\n",
      "[ SUCCESS ] BIN file: /Users/sanchit/Documents/Projects/openvino_opencv/./models/custom_crack_detection/fp32_crack_detection.bin\n",
      "[ SUCCESS ] Total execution time: 11.72 seconds. \n",
      "[ SUCCESS ] Memory consumed: 264280 MB. \n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model {INPUT_MODEL_FPATH} \\\n",
    "--output_dir {OUT_DIR} \\\n",
    "--input_shape [1,352,640,3] \\\n",
    "--model_name {MODEL_NAME} \\\n",
    "--data_type {DATA_TYPE} \\\n",
    "--log_level WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
